---
sidebar_position: 3
id: Regression Analysis and Feature Selection
title: Regression Analysis and Feature Selection
tags:
  - Study
  - Graduate
  - Data Mining
---

# Regression Analysis and Feature Selection

## 先来复习点基础概念

1. RSS (Residual Sum of Squares)：残差平方和  
    $$
    RSS = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
    $$

2. TSS (Total Sum of Squares)：总平方和  
    $$
    TSS = \sum_{i=1}^{n} (y_i - \bar{y})^2
    $$

3. ESS (Explained Sum of Squares)：回归平方和  
    $$
    ESS = \sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2
    $$
==> $$TSS = ESS + RSS$$

4. MSE (Mean Squared Error)：均方误差  
    $$
    MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
    $$

5. Variance：方差  
    $$
    Var(y) = \frac{1}{n} \sum_{i=1}^{n} (y_i - \bar{y})^2
    $$

==> $$ R^2 = VE = 1 - \frac{RSS}{TSS} = 1 - \frac{MSE}{Var(Y)} $$


## 线性回归

### 线性回归的假设

1. No Outliers: 没有`离群值`
2. No Multicollinearity: 没有`多重共线性` - 自变量之间的高相关性
3. No Heteroscedasticity: 没有`异方差性`

Hetroscedasticity （异方差性）: 指的是`残差`随着自变量的变化而变化，也就是**残差的方差不是常数**

### Fixing broken assumptions （解决假设不成立的情况）

1. Outliers: filter掉
2. Multicollinearity: 从高相关的自变量中选择一个作为代表
3. Heteroscedasticity: 使用`log`或`sqrt`等方法进行变换，转化数据以减少变化的不一致性

## 特征选择

### Statistical Test of Significance （统计显著性检验）

#### Hypothesis
- 特征的真实参数值为0 - F-test
- 特征对模型不是必要的 - T-test

#### Test Method
- T-test: 关注单个特征的重要性
- F-test: 关注多个特征组合的重要性 OR 在特征较多时，关注某个特征对模型的贡献

### Why Feature Selection?
1. Feature Variable ↑ =>  
    - computational Cost ↑
    - samples required to fit the model ↑
    - data sparsity ↑
2. Data expensive to collect & store
3. Not all features are useful
4. 维度太高没法可视化

### Feature Selection Methods

#### Filter Methods
- Unsupservised:  通过`特征之间`的关系来选择特征 -- e.g. 如果两个特征高度相关，选一个做代表
- Supervised: 通过特征与目标变量之间的关系来选择特征 -- e.g. 删掉相关性低的

#### Wrapper Methods

![Wrapper Methods](https://jcqn.oss-cn-beijing.aliyuncs.com/img_blog/514DM_3.png)

#### Embedded Methods
Use models that have built-in feature selection:  
- Lasso Regression
- Random Forest / Decision Trees

#### Feature extraction
The building of `derived` features, or the inference of `hidden` features, from an initial dataset（从原始数据集中构建`派生`特征，或从中推断`隐藏`特征）  
- Neural Networks
- Projection Methods: PCA, SVD...
