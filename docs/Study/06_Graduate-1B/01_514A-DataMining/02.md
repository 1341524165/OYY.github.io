---
sidebar_position: 2
id: Linear Regression and Gradient Descent Optimization
title: Linear Regression and Gradient Descent Optimization
tags:
  - Study
  - Graduate
  - Data Mining
---

# Linear Regression and Gradient Descent Optimization

### How does a model learn?

1. `Supervised learning (监督学习)`:  
Given examples of data, learn a model that can estimate the value of label variables from feature variables.
2. Unsupervised learning (监督学习):  
The given data is not labeled. And the model searches for patterns, but cannot assign meanings.

### Goal for `Supervised Learning`:
1. **Classification**: predict a discrete label.
2. **Regression**: predict a ordered quantitative value.  
    => So to optimize the model, we should solve 2 problems:  
    1. `Structure/Class` ?
    2. Parameters ?

### Funcion `Classes`

- Linear: $y = mx + b$
- Polynomial: $y = m_0 + m_1x + m_2x^2 + ... + m_nx^n$
- Exponential: $y = m(k)^x$
- Logarithmic: $y = log_k(x)$
- Logistic: $y = \frac{1}{1 + e^{-k(x - x_0)}}$

    1. How to pick `Class`?
    - Search the function space (搜索函数空间):  
    逐一搜索每种函数形式以找到最优的模型【但这在计算上是不可行的..
    - Domain knowledge (领域知识):  
    比如经济学可能时对数，物理问题可能是指数函数..【但这太limited
    - Visual inspection of data （数据可视化检查）:  
    【高维数据不直观
    - Occam's Razor (奥卡姆剃刀原则):
    在所有可能的模型中，选择最简单的那个，**最小化模型复杂度 -> 减少过拟合风险**【太简单可能不足以捕捉数据的复杂关系

    2. How to pick `Parameters`?