---
sidebar_position: 6
id: D-Learning
title: 图像处理与深度学习
tags:
  - Study
  - 3A
  - DeepLearning
---

## _图像处理与深度学习_

### 1.基本知识

#### 1.1 机器学习分类

**TEP**（Task 任务，Experience 经验，Performance 性能）

聚类：是指把相似的数据划分到一起，具体划分的时候`并不关心这一类的标签`，目标就是把相似的数据**聚合**到一起，聚类是一种**无监督学习方法；**  
分类：是把不同的数据划分开，其过程是`通过训练`数据集获得一个`分类器`，再通过分类器去预测未知数据，分类是一种**监督学习方法；**  
回归：拟合一条最接近数据变化规律的曲线

#### 1.2 卷积神经网络

卷积层：对**三维数组**及其**权重**的计算方式。卷积核（参数）在通过逐一滑动窗口计算而得  
池化/采样层：直接抽样选取极小局部的某一元素作为下一层的元素

卷积的作用：特征提取；  
池化的作用：特征降维；（池化层在两个卷积层间，仅压缩图形尺寸而不丢失信息）

#### 1.2 循环神经网络（RNN）

引入特性：**时序**处理序列数据（文本上下文）

对序列数据的处理：每次输入序列中的一个单元，然后保存每一个隐层神经元的计算结果，留给下一个输入时该神经元进行使用  
历史信息：保存的隐层单元计算结果，含有上一次输入的信息

#### 1.3 多层感知机（Multi-Layer Perceptron，MLP）

:::note
神经网络**基本单位：神经元**  
:::

多层前馈（全连接）神经网络 => 每层与下层连接；不同层连接；不跨层连接  
“前馈”不代表信号不能回传，而是指网络拓扑结构中不存在环或回路，其中：

输入层：仅接收外界输入，不进行函数处理；  
隐藏层 和 输出层：包含功能神经元，能将接收到的总输入值与一定的阈值进行比较，然后通过**激活函数**处理以产生神经元的输出

p.s. 若将阈值也作为输入信号在神经网络中标出，则除输出层之外，各层会多出一个固定输入为-1 的“哑结点”（dummy node），该节点与下一层的连接权即为阈值

##### 1.3.1. MLP 算法推导

:::info **_过程_**：以`识别手写数字`为例：

假设样本为 n 个手写数字图像，每个数字图像由 28×28 像素组成，每个像素由灰度值表示。  
我们把 28×28 的像素展开变成一个有 784 个维度的一维行向量，即一个样本向量，那么此时 =>  
`输入层`：每个神经元对应一个像素点，共 784 个神经元

因为是识别单个手写数字，其结果会有 0-9 这十种情况，因此 =>  
`输出层`：10 个神经元

`隐藏层`：层数以及单元数则作为要优化的额外超参数，设为 q
:::

p.s. 关于激活函数：  
理想的激活函数是如下图（a)所示的**阶跃函数**，它将输入值映射为输出值“0”或“1”，显然“1”对应于神经元兴奋，“0”对应于神经元抑制；  
然而，阶跃函数具有**不连续、不光滑**等不太好的性质，因此实际常用 **_Sigmoid 函数_**作为激活函数，如下图(b)所示。  
【有时，输出层神经元也采用线性激活函数，即直接以输入值 c 与阈值 θ 的比较结果作为最后的预测值 y’输出。】  
![sigmoid](https://tva2.sinaimg.cn/large/005x6vs8ly1h73ndg7bhtj31350j1di4.jpg)

##### 1.3.2 正向传播(Forward Propagation)：激活神经网络

n 个样本向量组成的矩阵 X 的维度为 n×784，每一行为一个样本向量；这也我们得到输入矩阵：  
![输入数据集矩阵](https://tvax2.sinaimg.cn/large/005x6vs8ly1h73o5g3eqdj33hw150my9.jpg)

而后，隐藏层输入数据：  
![输入层输出；隐藏层输入](https://tvax2.sinaimg.cn/large/005x6vs8ly1h73vhb35e4j32io1dggnw.jpg)

接下来，隐藏层的各个功能神经元将接收到的输入值 ah(h=1,2,…,q)，与某一阈值 γh(h=1,2,…,q)进行比较，  
然后通过激活函数 Sigmoid 处理产生神经元的输出 bh(h=1,2,…,q)，用公式表示为：  
![隐藏层数据处理](https://tvax2.sinaimg.cn/large/005x6vs8ly1h73vlubg3kj30aq01x748.jpg)

于是，隐藏层输出向量为：  
![隐藏层输出](https://tva2.sinaimg.cn/large/005x6vs8ly1h73vt0ydysj30ib01674e.jpg)

之后，隐藏层神经元的输出 bh(h=1,2,…,q)继续通过带权重的连接 w 传递至输出层，成为输出层的输入值 co(o=1,2,…,l)，  
同理，参照上面的 V 矩阵可知此处的 **W 的转置** 将是一个 **q×l** 的矩阵；

同理 Sigmoid 处理：  
![输出层数据处理](https://tva4.sinaimg.cn/large/005x6vs8ly1h73w06px2gj30aq01xaa0.jpg)

后得到：  
![输出层输出](https://tva2.sinaimg.cn/large/005x6vs8ly1h73w0qi42jj30in014jrh.jpg)

##### 1.3.3 逆向传播(Back Propagation)：学习权重系数及阈值

:::danger
对不起！因为没有彻底学完公式的推导，又不能只记半截，只好后续找机会补上  
麻瓜大脑看点矩阵的简单运算都花了不少时间/(ㄒ o ㄒ)/~~😥  
今后一定更加好好努力！！
:::
但至少应该学习一个最基本却应用十分广泛的的方法：**_梯度下降法(Gradient Descent)_**；  
梯度下降可以说是神经网络最常用的优化算法，其原理：

```markdown
目标函数 J(θ)关于参数 θ 的梯度将是损失函数（loss function）上升最快的方向。  
而我们要最小化 loss，只需要将参数沿着梯度相反的方向前进一个步长，就可以实现目标函数的下降。  
这个步长 η 又称为学习速率。
```

更新参数的公式为：
**θ = θ - η \* ∇J(θ)**

:::tip 来个有点不通俗易懂的通俗易懂的例子
损失函数上升的方向是坏的，把他当成比较累的上山；  
也就是说梯度就是上山；  
所以我们要最小化损失函数，也就是要往下山的方向前进步长；  
那么下山的速度也就是步长、学习速率 η。
:::

于是我们发现了步长 η 还是蛮重要的：  
![η_select](https://tva1.sinaimg.cn/large/005x6vs8ly1h78m34wwrrj30mc0a6aap.jpg)

回到数学上来，如下图所示：  
![image](https://tva4.sinaimg.cn/large/005x6vs8ly1h741djufmqj30pw04n403.jpg)
这种大幅的上下波动，减慢了梯度下降法的速度；  
且前文已知无法使用更大的学习率，因为如果用较大的学习率，可能降低效率甚至偏离函数的范围。

:::info 图中问题原因
虽然近处的步 η 长大，但因算术平均导致权重较小，这样对梯度下降速度影响的贡献不够大。
:::

这就要引入一个优化梯度下降算法的基本方法：  
**_指数加权平均_**：  
比如 t 时刻的观测值为 x(t) ，那么评估 t 时刻的**移动平均值**为:  
v(t) = η \* x(t) + (1 - η) \* v(t-1) `η 取 0~1`

递推展开后可知，x 的权重是在**指数递减**的  
也就是说，**最近的观测值对 v 的影响最大**，也即**横轴**上将学习得更快

进一步的，为了减少这些摆动，使得近处在**纵轴上的学习减速**，同理加权平均

于是我们就有了 **_动量法(Momentum)_**，  
它在每次计算梯度的迭代中，对 dw 和 db 使用了指数加权平均法的思想：  
![image](https://tvax1.sinaimg.cn/large/005x6vs8ly1h78m8zbmflj309g0au0u9.jpg)

并最终得到更高效的算法：  
![image](https://tvax1.sinaimg.cn/large/005x6vs8ly1h78mac83vsj30oy04sq4s.jpg)

### 2. 目标检测

图像理解的三个层次：

- 分类：关心整体【获取 **类别** 信息】
- 检测：关心特定的物体目标【获取 **类别 + 位置** 信息】
- 分割：关心物体的每个像素【获取 **类别 + 位置 + 像素类别（/实例）** 信息】

#### 2.1 R-CNN

##### 2.1.1 算法流程

· step1：候选区域选择： 一张图像生成 1k~2k 个候选区域（使用 SS 方法）  
· step2：特称提取： 对每个候选区域进行特征提取（使用 CNN）  
· step3：分类和边界回归：

- 对每个候选区域进行分类（使用 SVM）；
- 对每个候选区域进行边界回归（使用回归器模拟修正候选框的位置）

##### 2.1.2 step1-候选区域的生成

**Selective Search:**
· 首先通过的简单的聚类生成区域集合；
· 然后根据定义的相似度不断合并区域，生成更大的区域；【区域相似度考虑四个方面：颜色、纹理、尺寸、交叠】

##### 2.1.3 step2-特征提取

· 将 2k 个候选区域缩放到 227x227 pixel；
· 使用 AlexNet CNN 提取特征；
· 得到 4096 维的特征向量（4096 是 AlexNet 的最后一层全连接层的输出维度），得到 2000x4096 的特征矩阵

##### 2.1.4 step3-分类

· 2000x4096 的特征矩阵作为 SVM 的输入，得到 2000x20 的分类结果矩阵（20 是类别数）；
:::tip IoU 网络
对每个候选区域进行边界回归（使用回归器模拟修正候选框的位置）  
计算原理：IoU = 实际框与预测框的**交集** / 实际框与预测框的**并集**
:::
· 非极大值抑制（NMS）剔除重叠候选框：

- 选取置信度最高的候选框；
- 计算该候选框与其他候选框的 IoU；
- 去除 IoU 大于阈值的候选框；

##### 2.1.5 step4-边界回归

· 用 20 个回归器对 20 个类别中 NMS 挑选出的候选框进行回归，得到 20 个回归结果（修正后的 bounding box）；
· 用 CNN 输出的特征向量进行预测

##### 2.1.6 存在问题

- 大量重叠区域，速度慢；
- 过程繁琐：CNN，SVM，NMS，回归器；
- 特征提取所需空间大：AlexNet 和 CNN 都要遍历提取所有候选区域的特征；

#### 2.2 Fast R-CNN

· step1：候选区域选择： 一张图像生成 1k~2k 个候选区域（使用 SS 方法）
· step2：将图像输入网络得到相应的特征图，将候选框映射到特征图上，得到候选框的特征矩阵；
· step3：将每个矩阵 ROI pooling 到 7x7 的特征图上，而后展平通过全连接层得到预测结果
